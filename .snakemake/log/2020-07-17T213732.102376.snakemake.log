Building DAG of jobs...
Using shell: /bin/bash
Provided cores: 1
Rules claiming more threads will be scaled down.
Job counts:
	count	jobs
	1	all
	1	bcftools_call
	1	plot_quals
	1	samtools_index
	1	samtools_sort
	5

[Fri Jul 17 21:37:32 2020]
rule samtools_sort:
    input: mapped_reads/SRR2034333.1.bam
    output: sorted_reads/SRR2034333.1.bam
    jobid: 3
    wildcards: sample=SRR2034333.1

[Fri Jul 17 21:37:34 2020]
Finished job 3.
1 of 5 steps (20%) done

[Fri Jul 17 21:37:34 2020]
rule samtools_index:
    input: sorted_reads/SRR2034333.1.bam
    output: sorted_reads/SRR2034333.1.bam.bai
    jobid: 4
    wildcards: sample=SRR2034333.1

[Fri Jul 17 21:37:34 2020]
Finished job 4.
2 of 5 steps (40%) done

[Fri Jul 17 21:37:34 2020]
rule bcftools_call:
    input: data/genome.fa, sorted_reads/SRR2034333.1.bam, sorted_reads/SRR2034333.1.bam.bai
    output: calls/all.vcf
    jobid: 2

[Fri Jul 17 21:38:25 2020]
Finished job 2.
3 of 5 steps (60%) done

[Fri Jul 17 21:38:25 2020]
rule plot_quals:
    input: calls/all.vcf
    output: plots/quals.svg
    jobid: 1

[Fri Jul 17 21:38:28 2020]
Finished job 1.
4 of 5 steps (80%) done

[Fri Jul 17 21:38:28 2020]
localrule all:
    input: plots/quals.svg
    jobid: 0

[Fri Jul 17 21:38:28 2020]
Finished job 0.
5 of 5 steps (100%) done
Complete log: /Users/indumathiprakash/Documents/snakemake-tutorial/.snakemake/log/2020-07-17T213732.102376.snakemake.log
